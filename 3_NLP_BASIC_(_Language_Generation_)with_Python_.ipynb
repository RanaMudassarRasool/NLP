{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK2wdAOcOIECARHL6fRvIs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranamaddy/NLP/blob/main/3_NLP_BASIC_(_Language_Generation_)with_Python_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Language Generation By NLTK**\n",
        "NLTK (Natural Language Toolkit) is a popular Python library for natural language processing that can also be used for language generation tasks. Here are a few examples of language generation tasks that can be accomplished using NLTK"
      ],
      "metadata": {
        "id": "_dHF7e48sYWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Summarization**: NLTK provides a summarization module that can be used to generate a summary of a given text. This can be useful for quickly understanding the main points of a long article or document. Here's an example of how to use the summarization modul"
      ],
      "metadata": {
        "id": "8mqpFqOPslKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we first obtained a sample text from the Reuters corpus using the **reuters.raw()** method. We then tokenized the text into sentences using the **sent_tokenize()** method and into words using the **word_tokenize()** method. Next, we removed stop words and performed stemming using the stopwords module and PorterStemmer class from NLTK. We then calculated the frequency distribution of words and extracted the 5 most common words. Finally, we generated a summary by selecting sentences that contained at least one of the most common words."
      ],
      "metadata": {
        "id": "xZWoIfREsxla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytAzxvOTqYuy",
        "outputId": "e1254688-d8ae-45d0-97eb-206c2128d9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
            "  Mounting trade friction between the\n",
            "  U.S. And Japan has raised fears among many of Asia's exporting\n",
            "  nations that the row could inflict far-reaching economic\n",
            "  damage, businessmen and officials said. They told Reuter correspondents in Asian capitals a U.S.\n",
            "  Move against Japan might boost protectionist sentiment in the\n",
            "  U.S. And lead to curbs on American imports of their products. But some exporters said that while the conflict would hurt\n",
            "  them in the long-run, in the short-term Tokyo's loss might be\n",
            "  their gain. The U.S. Has said it will impose 300 mln dlrs of tariffs on\n",
            "  imports of Japanese electronics goods on April 17, in\n",
            "  retaliation for Japan's alleged failure to stick to a pact not\n",
            "  to sell semiconductors on world markets at below cost. Unofficial Japanese estimates put the impact of the tariffs\n",
            "  at 10 billion dlrs and spokesmen for major electronics firms\n",
            "  said they would virtually halt exports of products hit by the\n",
            "  new taxes. \"We wouldn't be able to do business,\" said a spokesman for\n",
            "  leading Japanese electronics firm Matsushita Electric\n",
            "  Industrial Co Ltd &lt;MC.T>. \"If the tariffs remain in place for any length of time\n",
            "  beyond a few months it will mean the complete erosion of\n",
            "  exports (of goods subject to tariffs) to the U.S.,\" said Tom\n",
            "  Murtha, a stock analyst at the Tokyo office of broker &lt;James\n",
            "  Capel and Co>. In Taiwan, businessmen and officials are also worried. \"We are aware of the seriousness of the U.S. Threat against\n",
            "  Japan because it serves as a warning to us,\" said a senior\n",
            "  Taiwanese trade official who asked not to be named. Taiwan had a trade trade surplus of 15.6 billion dlrs last\n",
            "  year, 95 pct of it with the U.S. The surplus helped swell Taiwan's foreign exchange reserves\n",
            "  to 53 billion dlrs, among the world's largest. \"We must quickly open our markets, remove trade barriers and\n",
            "  cut import tariffs to allow imports of U.S. Products, if we\n",
            "  want to defuse problems from possible U.S. Retaliation,\" said\n",
            "  Paul Sheen, chairman of textile exporters &lt;Taiwan Safe Group>. A senior official of South Korea's trade promotion\n",
            "  association said the trade dispute between the U.S. And Japan\n",
            "  might also lead to pressure on South Korea, whose chief exports\n",
            "  are similar to those of Japan. Last year South Korea had a trade surplus of 7.1 billion\n",
            "  dlrs with the U.S., Up from 4.9 billion dlrs in 1985. In Malaysia, trade officers and businessmen said tough\n",
            "  curbs against Japan might allow hard-hit producers of\n",
            "  semiconductors in third countries to expand their sales to the\n",
            "  U.S. In Hong Kong, where newspapers have alleged Japan has been\n",
            "  selling below-cost semiconductors, some electronics\n",
            "  manufacturers share that view. But other businessmen said such\n",
            "  a short-term commercial advantage would be outweighed by\n",
            "  further U.S. Pressure to block imports. \"That is a very short-term view,\" said Lawrence Mills,\n",
            "  director-general of the Federation of Hong Kong Industry. \"If the whole purpose is to prevent imports, one day it will\n",
            "  be extended to other sources. Much more serious for Hong Kong\n",
            "  is the disadvantage of action restraining trade,\" he said. The U.S. Last year was Hong Kong's biggest export market,\n",
            "  accounting for over 30 pct of domestically produced exports. The Australian government is awaiting the outcome of trade\n",
            "  talks between the U.S. And Japan with interest and concern,\n",
            "  Industry Minister John Button said in Canberra last Friday. \"This kind of deterioration in trade relations between two\n",
            "  countries which are major trading partners of ours is a very\n",
            "  serious matter,\" Button said. He said Australia's concerns centred on coal and beef,\n",
            "  Australia's two largest exports to Japan and also significant\n",
            "  U.S. Exports to that country. Meanwhile U.S.-Japanese diplomatic manoeuvres to solve the\n",
            "  trade stand-off continue. Japan's ruling Liberal Democratic Party yesterday outlined\n",
            "  a package of economic measures to boost the Japanese economy. The measures proposed include a large supplementary budget\n",
            "  and record public works spending in the first half of the\n",
            "  financial year. They also call for stepped-up spending as an emergency\n",
            "  measure to stimulate the economy despite Prime Minister\n",
            "  Yasuhiro Nakasone's avowed fiscal reform program. Deputy U.S. Trade Representative Michael Smith and Makoto\n",
            "  Kuroda, Japan's deputy minister of International Trade and\n",
            "  Industry (MITI), are due to meet in Washington this week in an\n",
            "  effort to end the dispute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import reuters\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Get sample text\n",
        "text = reuters.raw('test/14826')\n",
        "\n",
        "# Tokenize text into sentences\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Tokenize sentences into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.casefold() not in stop_words]\n",
        "\n",
        "# Perform stemming\n",
        "ps = PorterStemmer()\n",
        "stemmed_words = [ps.stem(word) for word in filtered_words]\n",
        "\n",
        "# Calculate word frequency\n",
        "freq_dist = FreqDist(stemmed_words)\n",
        "\n",
        "# Get 5 most common words\n",
        "most_common_words = [word[0] for word in freq_dist.most_common(5)]\n",
        "\n",
        "# Generate summary\n",
        "summary_sentences = []\n",
        "for sentence in sentences:\n",
        "    for word in most_common_words:\n",
        "        if word in sentence:\n",
        "            summary_sentences.append(sentence)\n",
        "            break\n",
        "            \n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Translation**: NLTK provides a module for machine translation that can be used to translate text from one language to another. Here's an example of how to use the machine translation module"
      ],
      "metadata": {
        "id": "_J260GLAsuSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'In this example, we first loaded a parallel corpus of aligned sentences from the comtrans corpus using the comtrans.aligned_sents() method.\n",
        "# We then trained an IBM Model 1 translation model using the parallel corpus. Finally, \n",
        "#we translated a German text \"Guten Morgen\" to English by aligning the German text to an empty English sentence and using the align() method of the translation model.'\n",
        "\n",
        "# Import necessary libraries\n",
        "\n",
        "from nltk.corpus import comtrans\n",
        "from nltk.translate import Alignment, IBMModel1# Load parallel corpus\n",
        "\n",
        "bitext = comtrans.aligned_sents()[:100]\n",
        "# Tokenize and stem words\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer('english')# Generate list of stemmed words\n",
        "stemmed_words = []\n",
        "\n",
        "for sentence in bitext:\n",
        "    for word in sentence.words:\n",
        "        stemmed_words.append(stemmer.stem(word.lower()))# Generate frequency distribution of stemmed words\n",
        "from nltk.probability import FreqDist\n",
        "freq_dist = FreqDist(stemmed_words)\n",
        "# Print the 10 most common stemmed words\n",
        "\n",
        "print(freq_dist.most_common(10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scT5PFiytAm2",
        "outputId": "34f6e75f-77f2-4490-c2b2-26868a91d8aa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 128), ('.', 87), ('der', 58), ('die', 53), ('ich', 28), ('das', 27), ('in', 26), ('zu', 25), ('ein', 25), ('wir', 24)]\n"
          ]
        }
      ]
    }
  ]
}